# -*- coding: utf-8 -*-
"""CIFAR10  NANO tensorflow

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/vinimuchulski/cifar10-nano-tensorflow.e8ba8407-f9c0-44a6-a6aa-3aa422ffa902.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250709/auto/storage/goog4_request%26X-Goog-Date%3D20250709T201517Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dc08d8c17bbd88b99939b0014eeb5bcb4007c2dfaaeec8afbc31366065a6051e8cacb2f577a4ad0e8975a99cc80e4f169e06fb2f81edc48ef8024752cf627147b62f7a7a5bfbb127c23de814cf65ee0971f1a8fa021d7ed35602196b4c42ae58cbe330b234ed6d603414b1bc80ff1556cefbb825f0d6f0d94d7f796b023de5b380f4efa6dff74d6a4e9173aaecc3016969bcd0b8fa651f5b8be5454d592ae609955c4c32e231202581a8ae25562d7a6fd99e86b001b14f3201afe9f70dc844ed4c7b7da2aefeb08d3406c710c2d3867b3ebfebbffea55521ea3396d9b7d7e5ce26791da2ba67b34d10ed2dc213cd5f1d2c6ca1af50c0fa71b5e605d805992ae2a
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

from tensorflow.keras import datasets, layers, models

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

import os
import logging
import warnings

logging.getLogger("tensorflow").setLevel(logging.ERROR)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.filterwarnings('ignore')

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()


x_train = x_train.astype("float32") / 255.0
x_test  = x_test.astype("float32")  / 255.0

# -------------------------------------------------------------------
# 1) Configura√ß√µes gerais (hiperpar√¢metros, caminhos, etc)
# -------------------------------------------------------------------

EPOCHS       = 30
BATCH_SIZE   = 128
VALID_SPLIT  = 0.1
MODEL_PATH   = "best_cifar10_model.h5"
TFLITE_PATH  = "cifar10_simple.tflite"
PATIENCE_ES  = 10
MONITOR_MET  = "val_loss"


# -------------------------------------------------------------------
# 2) Helpers
# -------------------------------------------------------------------
def get_callbacks():
    return [
        EarlyStopping(monitor=MONITOR_MET, patience=PATIENCE_ES, verbose=0, restore_best_weights=True),
        ModelCheckpoint(MODEL_PATH,   monitor=MONITOR_MET, save_best_only=True, verbose=0)
    ]

def plot_history(history):
    plt.figure(figsize=(12,4))

    # Loss
    plt.subplot(1,2,1)
    plt.plot(history.history["loss"], label="train")
    plt.plot(history.history[MONITOR_MET], label="val")
    plt.title("Loss")
    plt.legend()

    # Accuracy
    plt.subplot(1,2,2)
    plt.plot(history.history["accuracy"], label="train")
    plt.plot(history.history["val_accuracy"], label="val")
    plt.title("Accuracy")
    plt.legend()

    plt.show()

def evaluate_model(model, x_test, y_test):
    loss, acc = model.evaluate(x_test, y_test, verbose=0)
    print(f"Acur√°cia final no test set: {acc:.4f}")
    return loss, acc

def export_tflite(model, filename=TFLITE_PATH):
    print(f"Convertendo modelo para TFLite em `{filename}`...")
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    with open(filename, "wb") as f:
        f.write(tflite_model)
    print("‚úÖ Export conclu√≠do.")
    #return tflite_model




def create_balanced_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(32, 32, 3)),

        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'), # Conv2D
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Dropout(0.25),

        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'), # Conv2D
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'), # Conv2D
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Dropout(0.2),

        tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'), # Conv2D
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dropout(0.3),

        tf.keras.layers.Dense(10, activation='softmax')
    ])
    return model

# 3. Orquestra√ß√£o do pipeline CIFAR-10 em uma √∫nica c√©lula

print("üî® Criando e compilando modelo para CIFAR-10")
model = create_balanced_model()
model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)
model.summary()

print(f"\nüöÇ Iniciando treino por {EPOCHS} epochs (batch size={BATCH_SIZE})")
history = model.fit(
    x_train, y_train,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_split=VALID_SPLIT,
    callbacks=get_callbacks(),
    verbose=1
)

print("\nüìä Plotando curva de treino")
plot_history(history)

print("\nüîç Avaliando no conjunto de teste")
evaluate_model(model, x_test, y_test)

print("\nüõ† Exportando modelo para TFLite")
export_tflite(model, TFLITE_PATH)

print("\nüìä Plotando curva de treino")
plot_history(history)

print("\nüîç Avaliando no conjunto de teste")
evaluate_model(model, x_test, y_test)

"""# Quantizar modelo para int8"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os

CLASS_NAMES = [
    "airplane", "automobile", "bird", "cat", "deer",
    "dog", "frog", "horse", "ship", "truck"
]
QUANTIZED_MODEL_FILENAME = "cifar10_simple_int8.tflite"

def convert_to_tflite_quantized(keras_model, representative_data, filename):
    print("Converting to TFLite with full integer quantization...")

    def representative_dataset_gen():
        for i in range(len(representative_data)):
            yield [representative_data[i:i+1]]

    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = representative_dataset_gen
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8

    tflite_quant_model = converter.convert()

    with open(filename, "wb") as f:
        f.write(tflite_quant_model)

    size_kb = os.path.getsize(filename) / 1024
    print(f"Quantized model saved to {filename} ({size_kb:.1f} KB)")
    return tflite_quant_model

def run_quantized_inference(tflite_model_content, float_image_sample):
    interpreter = tf.lite.Interpreter(model_content=tflite_model_content)
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]

    scale, zero_point = input_details["quantization"]
    quantized_input = (float_image_sample / scale + zero_point).astype(input_details["dtype"])

    interpreter.set_tensor(input_details["index"], quantized_input)
    interpreter.invoke()

    quantized_output = interpreter.get_tensor(output_details["index"])
    out_scale, out_zero_point = output_details["quantization"]
    float_output = (quantized_output.astype(np.float32) - out_zero_point) * out_scale

    predicted_label = np.argmax(float_output)
    return predicted_label

def plot_prediction(image, true_name, pred_name):
    plt.figure(figsize=(4, 4))
    plt.imshow(image)
    plt.title(f"True: {true_name}\nPredicted: {pred_name}")
    plt.axis('off')
    plt.show()

model = tf.keras.models.load_model('/kaggle/working/best_cifar10_model.h5')

(x_train, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
x_train = x_train.astype("float32") / 255.0
x_test  = x_test.astype("float32")  / 255.0

representative_data = x_train[:200]
tflite_model_content = convert_to_tflite_quantized(
    keras_model=model,
    representative_data=representative_data,
    filename=QUANTIZED_MODEL_FILENAME
)

print("\nVerifying inference with the INT8 model...")
test_index      = 10
image_sample    = x_test[test_index:test_index+1]
true_label      = int(y_test[test_index][0])
true_name       = CLASS_NAMES[true_label]
predicted_label = run_quantized_inference(tflite_model_content, image_sample)
pred_name       = CLASS_NAMES[predicted_label]

print(f"True Class:      {true_label} ({true_name})")
print(f"Predicted Class: {predicted_label} ({pred_name})")
plot_prediction(image_sample[0], true_name, pred_name)

def evaluate_tflite_model(model_path, x_test, y_test):
    if not os.path.exists(model_path):
        print(f"Erro: Arquivo do modelo n√£o encontrado em '{model_path}'")
        return None

    interpreter = tf.lite.Interpreter(model_path=model_path)
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]

    input_scale, input_zero_point = input_details["quantization"]
    output_scale, output_zero_point = output_details["quantization"]
    input_dtype = input_details["dtype"]

    correct_predictions = 0
    total_images = len(x_test)

    for i in range(total_images):
        image = x_test[i]
        true_label = y_test[i][0]

        quantized_input = (image / input_scale) + input_zero_point
        quantized_input = np.expand_dims(quantized_input, axis=0).astype(input_dtype)

        interpreter.set_tensor(input_details['index'], quantized_input)
        interpreter.invoke()

        quantized_output = interpreter.get_tensor(output_details['index'])[0]
        dequantized_output = (quantized_output.astype(np.float32) - output_zero_point) * output_scale

        predicted_label = np.argmax(dequantized_output)

        if predicted_label == true_label:
            correct_predictions += 1

    accuracy = correct_predictions / total_images
    return accuracy

TFLITE_MODEL_PATH = 'cifar10_simple_int8.tflite'

(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
x_test = x_test.astype("float32") / 255.0

final_accuracy = evaluate_tflite_model(
    model_path=TFLITE_MODEL_PATH,
    x_test=x_test,
    y_test=y_test
)

if final_accuracy is not None:
    print(f"Modelo: {TFLITE_MODEL_PATH}")
    print(f"Imagens de teste: {len(x_test)}")
    print(f"Acur√°cia final no dataset de teste: {final_accuracy:.4f}")